{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eefa45b3",
   "metadata": {},
   "source": [
    "# Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63dc427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd2aa54",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc6d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TOKEN_SPAM_PROB_FILE = 'SpamData/03_Testing/prob-spam.txt'\n",
    "TOKEN_HAM_PROB_FILE = 'SpamData/03_Testing/prob-nonspam.txt'\n",
    "TOKEN_ALL_PROB_FILE = 'SpamData/03_Testing/prob-all-tokens.txt'\n",
    "\n",
    "TEST_FEATURE_MATRIX = 'SpamData/03_Testing/test-features.txt' \n",
    "TEST_TARGET_FILE = 'SpamData/03_Testing/test-target.txt' \n",
    "\n",
    "VOCAB_SIZE = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2926d6",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631399ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.loadtxt(TEST_FEATURE_MATRIX, delimiter=' ')\n",
    "y_test = np.loadtxt(TEST_TARGET_FILE, delimiter=' ')\n",
    "\n",
    "prob_token_spam = np.loadtxt(TOKEN_SPAM_PROB_FILE, delimiter=' ')\n",
    "prob_token_ham = np.loadtxt(TOKEN_HAM_PROB_FILE, delimiter=' ')\n",
    "prob_all_tokens = np.loadtxt(TOKEN_ALL_PROB_FILE, delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0880fd8",
   "metadata": {},
   "source": [
    "# Calculating the Joint Probability\n",
    "\n",
    "### The Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8942972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1724, 2500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279975a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_token_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2063c62e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1724,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dot(prob_token_spam).shape # I can't do it this way => prob_token_spam.dot(X_test).shape because \n",
    "# the values are not aligned [(1724, 2500)] * [(2500,)] != [(2500,)] * [(1724, 2500)]. where the former is\n",
    "# the correct way of doing it since the col of the first matrix(2500 )is aligned properly with the row of the second matrix(2500 )\n",
    "# also this is the right way to do it since we are multiplying the column of the 2d array by the row of the 1d array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1723e6c4",
   "metadata": {},
   "source": [
    "## Set the Prior\n",
    "\n",
    "## $$ P(Spam \\, | \\, X) =  \\frac{P(X \\, | \\, Spam \\,) \\, P(Spam)} {P(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a3b53",
   "metadata": {},
   "source": [
    "<p> A prior is a belief or guess about a quantity. In our case, we already have a calculated \"guess\", which is the probability of spam = 0.3109 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d97519",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROB_SPAM = 0.3109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e0dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.40768141,  -5.25375622,  -4.99015865, ...,  -9.79171765,\n",
       "        -9.52935339, -10.70800838])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(prob_token_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8394e658",
   "metadata": {},
   "source": [
    "## Joint Probability in Log Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b419ab09",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.26609396,  2.15741368, 20.58593663, 17.73868148, 20.49790994])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_spam = X_test.dot(np.log(prob_token_spam) - np.log(prob_all_tokens)) + np.log(PROB_SPAM)\n",
    "joint_log_spam[:5]\n",
    "# since we are using log format instead of dividing by p(X) we'll subtract the prob_token_spam from \n",
    "# prob_all_tokens and also we won't be multiplying against the p(Spam) rather we'll be adding it up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1fda3",
   "metadata": {},
   "source": [
    "## $$ P(Ham \\, | \\, X) =  \\frac{P(X \\, | \\, Ham \\,) \\, (1 - P(Spam) )} {P(X)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6de56455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-60.9615197 , -11.00803242, -37.96485145, -59.12449324,\n",
       "       -53.78250218])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_ham = X_test.dot(np.log(prob_token_ham) - np.log(prob_all_tokens)) + np.log(1 - PROB_SPAM)\n",
    "joint_log_ham[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afddafe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1724"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_ham.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63f60bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1724"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_spam.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4735c2c",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "### Checking for the Higher Joint Probability\n",
    "\n",
    "$$ P(Spam \\, | \\, X) >  P(Ham \\, | \\, X) $$\n",
    "<br>\n",
    "<center><b> OR </b></center>\n",
    "<br>\n",
    "$$ P(Spam \\, | \\, X) <  P(Ham \\, | \\, X) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "557a65fe",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for i in range(1724):\n",
    "    if joint_log_spam[i] > joint_log_ham[i]:\n",
    "        prediction.append(1)\n",
    "    elif joint_log_ham[i] > joint_log_spam[i]:\n",
    "        prediction.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f6f10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e908b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1724"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "045d5215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35704188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2885a44",
   "metadata": {},
   "source": [
    "### Simplifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4b332ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_log_spam = X_test.dot(np.log(prob_token_spam)) + np.log(PROB_SPAM)\n",
    "joint_log_ham = X_test.dot(np.log(prob_token_ham)) + np.log(1 - PROB_SPAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9febc",
   "metadata": {},
   "source": [
    "<p> I can do what I did above because since we are trying to predict  if an email is spam or not , that prediction won't depend on p(X) which was represented by \"- np.log(prob_all_tokens)\". And so removing that part of the code won't break the calculation </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb845cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
